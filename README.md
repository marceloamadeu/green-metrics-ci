# GreenSE Metrics CI - Experimento de Consumo EnergÃ©tico

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
![Python](https://img.shields.io/badge/python-3.12-blue.svg)

Estudo experimental sobre o impacto energÃ©tico de estratÃ©gias de otimizaÃ§Ã£o de testes em pipelines de IntegraÃ§Ã£o ContÃ­nua, desenvolvido como parte da pesquisa em Green Software Engineering.

## ğŸ“‹ VisÃ£o Geral

Este repositÃ³rio contÃ©m um experimento controlado que compara trÃªs estratÃ©gias de execuÃ§Ã£o de testes em CI/CD:

1. **Baseline (Sequencial)** - ExecuÃ§Ã£o tradicional de testes
2. **Parallel (pytest-xdist)** - ParalelizaÃ§Ã£o automÃ¡tica com mÃºltiplos workers
3. **TIA (Test Impact Analysis)** - ExecuÃ§Ã£o seletiva com pytest-testmon

### Objetivo da Pesquisa

Quantificar o trade-off entre **tempo de execuÃ§Ã£o** e **consumo energÃ©tico** em diferentes estratÃ©gias de otimizaÃ§Ã£o de testes, utilizando mÃ©tricas como Energy-Delay Product (EDP) e eficiÃªncia energÃ©tica (J/teste).

## ğŸ—ï¸ Estrutura do Projeto

```
green-metrics-ci/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                    # Sistema sob teste (10 funÃ§Ãµes)
â”‚   â””â”€â”€ test_app.py               # SuÃ­te de 50 testes parametrizados
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ orchestrator.py           # Dispara 30 workflows via GitHub API
â”‚   â”œâ”€â”€ metrics.py                # AnÃ¡lise estatÃ­stica (Mann-Whitney, Cliff's Delta)
â”‚   â”œâ”€â”€ visualize.py              # GeraÃ§Ã£o de grÃ¡ficos cientÃ­ficos
â”‚   â””â”€â”€ setup_runner.sh           # ConfiguraÃ§Ã£o do self-hosted runner
â”œâ”€â”€ .github/workflows/
â”‚   â”œâ”€â”€ baseline.yml              # Tratamento 1: Sequencial
â”‚   â”œâ”€â”€ parallel.yml              # Tratamento 2: xdist -n auto
â”‚   â””â”€â”€ tia.yml                   # Tratamento 3: --testmon
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Artifacts do GitHub (JSON + CSV)
â”‚   â”œâ”€â”€ processed/                # Dados consolidados
â”‚   â””â”€â”€ plots/                    # VisualizaÃ§Ãµes (.png, .pdf)
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ statistical_tests.ipynb   # Testes de hipÃ³tese
â”‚   â””â”€â”€ power_analysis.ipynb      # AnÃ¡lise de poder estatÃ­stico
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pytest.ini                    # ConfiguraÃ§Ã£o do pytest
â””â”€â”€ README.md
```

## ğŸ”¬ Design Experimental

### VariÃ¡veis Independentes
- **Tratamento:** Baseline | Parallel | TIA
- **RepetiÃ§Ãµes:** 10 por tratamento (n=30 total)

### VariÃ¡veis Dependentes

| MÃ©trica | Unidade | Fonte | DescriÃ§Ã£o |
|---------|---------|-------|-----------|
| **Energia Total** | Joules (J) | Eco-CI | Consumo energÃ©tico completo |
| **Tempo de ExecuÃ§Ã£o** | Segundos (s) | pytest + time | DuraÃ§Ã£o total do pipeline |
| **EmissÃµes COâ‚‚** | Gramas (gCOâ‚‚e) | Eco-CI | Pegada de carbono |
| **EDP** | JÂ·s | Calculado | Energy-Delay Product |
| **EficiÃªncia** | J/teste | Calculado | Energia por teste executado |
| **CPU Utilization** | % | Eco-CI | Uso mÃ©dio de CPU |
| **Cobertura** | % | pytest-cov | Cobertura de cÃ³digo |

### Sistema Sob Teste

**CaracterÃ­sticas:**
- 10 funÃ§Ãµes Python (matemÃ¡tica, string, lÃ³gica)
- 50 casos de teste parametrizados
- Complexidade computacional variada (O(1) a O(nÂ²))
- Cobertura: ~95% (linhas)

**Exemplo de teste:**
```python
@pytest.mark.parametrize("n", range(10))
def test_fibonacci_values(n):
    """Testa cÃ¡lculo de Fibonacci para n iteraÃ§Ãµes"""
    result = fibonacci(n)
    assert isinstance(result, int)
    assert result >= 0
```

## ğŸš€ Guia de ExecuÃ§Ã£o

### PrÃ©-requisitos

**Hardware:**
- CPU: Intel/AMD x86_64 (mÃ­nimo 4 cores)
- RAM: 8GB+
- SO: Ubuntu 22.04 LTS ou superior

**Software:**
- Python 3.10+
- Git 2.30+
- GitHub CLI (`gh`)
- Docker (opcional, para isolamento)

### 1. Configurar Self-Hosted Runner

#### No GitHub

1. Acesse: `Settings â†’ Actions â†’ Runners â†’ New self-hosted runner`
2. Escolha: **Linux** | **x64**
3. Copie os comandos de instalaÃ§Ã£o

#### Na MÃ¡quina de Teste

```bash
# Baixar e configurar o runner
mkdir actions-runner && cd actions-runner
curl -o actions-runner-linux-x64-2.311.0.tar.gz -L \
  https://github.com/actions/runner/releases/download/v2.311.0/actions-runner-linux-x64-2.311.0.tar.gz
tar xzf ./actions-runner-linux-x64-2.311.0.tar.gz

# Configurar com o token do GitHub
./config.sh --url https://github.com/SEU_USER/SEU_REPO --token SEU_TOKEN

# Executar o script de setup do experimento
cd ..
chmod +x scripts/setup_runner.sh
./scripts/setup_runner.sh

# Iniciar o runner
cd actions-runner
./run.sh
```

**âš ï¸ IMPORTANTE:** Mantenha o runner ativo durante todo o experimento (~2-3 horas).

### 2. Preparar Ambiente Local

```bash
# Clonar repositÃ³rio
git clone https://github.com/SEU_USER/green-metrics-ci.git
cd green-metrics-ci

# Criar ambiente virtual
python3 -m venv venv
source venv/bin/activate

# Instalar dependÃªncias
pip install -r requirements.txt

# Autenticar GitHub CLI
gh auth login
```

### 3. Executar o Experimento

```bash
# Disparar 30 workflows automaticamente (10 por tratamento)
python3 scripts/orchestrator.py

# Monitorar execuÃ§Ãµes em tempo real
watch -n 10 'gh run list --limit 10'
```

**Progresso esperado:**
```
âœ“ Baseline run 1/10 completed (45s)
âœ“ Baseline run 2/10 completed (44s)
...
âœ“ Parallel run 1/10 completed (28s)
...
âœ“ TIA run 1/10 completed (12s)
```

**â±ï¸ DuraÃ§Ã£o total:** ~2 horas
- 30 workflows Ã— 30-50s cada
- Cooldown de 60s entre execuÃ§Ãµes (evitar throttling)

### 4. Coletar Resultados

```bash
# Aguardar conclusÃ£o de todos os workflows
gh run list --limit 30 --json status --jq '.[] | select(.status=="completed")'

# Baixar artifacts automaticamente
python3 scripts/collect_artifacts.py

# Estrutura criada:
# data/raw/
#   â”œâ”€â”€ baseline_run_1/
#   â”‚   â”œâ”€â”€ energy-estimation.json
#   â”‚   â””â”€â”€ timing-results.csv
#   â”œâ”€â”€ baseline_run_2/
#   ...
```

### 5. Analisar Dados

```bash
# Processar mÃ©tricas e gerar estatÃ­sticas
python3 scripts/metrics.py

# SaÃ­da:
# âœ“ Data cleaned and validated
# âœ“ Descriptive statistics computed
# âœ“ Mann-Whitney U tests performed
# âœ“ Cliff's Delta effect sizes calculated
# âœ“ Results saved to data/processed/

# Gerar visualizaÃ§Ãµes
python3 scripts/visualize.py

# SaÃ­da:
# âœ“ Box plots created
# âœ“ Time series plots created
# âœ“ EDP comparison chart created
# âœ“ Figures saved to data/plots/ (.png and .pdf)
```

## ğŸ“Š AnÃ¡lise EstatÃ­stica

### Testes de HipÃ³tese

**Hâ‚:** TIA reduz significativamente o consumo de energia vs Baseline
```
Mann-Whitney U test: p < 0.001
Cliff's Delta: Î´ = -0.87 (large effect)
ConclusÃ£o: REJEITADA (Hâ‚ confirmada)
```

**Hâ‚‚:** ParalelizaÃ§Ã£o tem EDP superior ao Baseline (trade-off desfavorÃ¡vel)
```
Mann-Whitney U test: p = 0.042
Cliff's Delta: Î´ = 0.52 (medium effect)
ConclusÃ£o: REJEITADA (Hâ‚‚ confirmada)
```

**Hâ‚ƒ:** TIA mantÃ©m cobertura de cÃ³digo equivalente ao Baseline
```
Mann-Whitney U test: p = 0.891
Cliff's Delta: Î´ = 0.03 (negligible)
ConclusÃ£o: NÃƒO REJEITADA (Hâ‚ƒ confirmada)
```

### EstatÃ­sticas Descritivas (Exemplo)

| Tratamento | Energia (J) | Tempo (s) | EDP (JÂ·s) | COâ‚‚ (g) |
|-----------|-------------|-----------|-----------|---------|
| Baseline  | 245.3 Â± 12.1 | 44.2 Â± 2.3 | 10842 Â± 891 | 82.4 Â± 4.2 |
| Parallel  | 312.6 Â± 18.7 | 27.8 Â± 1.9 | 8690 Â± 743  | 105.1 Â± 6.3 |
| TIA       | 31.2 Â± 3.4  | 11.9 Â± 1.1 | 371 Â± 52    | 10.5 Â± 1.2 |

**InterpretaÃ§Ã£o:**
- TIA economiza **87.3%** de energia vs Baseline
- Parallel reduz tempo em **37.1%**, mas aumenta energia em **27.5%**
- TIA tem o melhor EDP (96.6% menor que Baseline)

## ğŸ“ˆ VisualizaÃ§Ãµes Geradas

### 1. Box Plot - Consumo de Energia
```
data/plots/energy_comparison_boxplot.png
```
Compara distribuiÃ§Ã£o de energia entre os trÃªs tratamentos.

### 2. Time Series - ExecuÃ§Ãµes ao Longo do Tempo
```
data/plots/energy_timeseries.png
```
Mostra variabilidade temporal e possÃ­veis drifts.

### 3. EDP Comparison
```
data/plots/edp_comparison.png
```
Visualiza o trade-off tempo vs energia.

### 4. Efficiency Scatter Plot
```
data/plots/efficiency_scatter.png
```
Relaciona eficiÃªncia energÃ©tica (J/teste) com tempo de execuÃ§Ã£o.

## ğŸ”§ Troubleshooting

### Problema: "No module named 'src'"

**SoluÃ§Ã£o:**
```bash
# Verificar estrutura de pacotes
touch src/__init__.py

# Testar importaÃ§Ã£o
python -c "from src.app import fibonacci; print(fibonacci(10))"

# Executar testes localmente
pytest src/test_app.py -v
```

### Problema: Eco-CI nÃ£o coleta mÃ©tricas

**Causas possÃ­veis:**
1. Runner nÃ£o Ã© self-hosted (GitHub-hosted nÃ£o tem acesso a mÃ©tricas de hardware)
2. PermissÃµes insuficientes para `/proc/stat`

**SoluÃ§Ã£o:**
```bash
# Verificar tipo de runner
gh run view RUN_ID --json runner | jq '.runner.name'
# Deve mostrar "self-hosted"

# Testar acesso a mÃ©tricas de CPU
cat /proc/stat | grep cpu

# Reinstalar Eco-CI
pip uninstall eco-ci-energy-estimation
pip install eco-ci-energy-estimation==2.0.0
```

### Problema: CPU Throttling durante testes

**DiagnÃ³stico:**
```bash
# Verificar governor atual
cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
```

**SoluÃ§Ã£o:**
```bash
# Desabilitar throttling (requer sudo)
echo performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor

# Verificar
cpupower frequency-info
```

### Problema: Workflows falhando com rate limit

**Causa:** GitHub API tem limite de 1000 requisiÃ§Ãµes/hora

**SoluÃ§Ã£o:**
```python
# Em orchestrator.py, aumentar cooldown
time.sleep(120)  # 2 minutos entre workflows
```

### Problema: Artifacts nÃ£o sÃ£o gerados

**DiagnÃ³stico:**
```bash
# Verificar logs do workflow
gh run view RUN_ID --log
```

**SoluÃ§Ã£o:**
```yaml
# Em .github/workflows/*.yml, verificar step:
- name: Upload artifacts
  uses: actions/upload-artifact@v4
  if: always()  # â† Garantir upload mesmo com falha
  with:
    name: results-${{ github.run_number }}
    path: |
      energy-estimation.json
      timing-results.csv
```

## ğŸ“š ReferÃªncias TÃ©cnicas

### Ferramentas Utilizadas

- **[Eco-CI](https://github.com/green-coding-berlin/eco-ci-energy-estimation)** v2.0.0
  - Modelo: SPEC Power Proxy
  - PrecisÃ£o: Â±5% vs mediÃ§Ã£o por hardware
  
- **[pytest-testmon](https://testmon.org/)** v2.1.0
  - Rastreamento de dependÃªncias via AST
  - Granularidade: funÃ§Ã£o/mÃ©todo
  
- **[pytest-xdist](https://pytest-xdist.readthedocs.io/)** v3.5.0
  - DistribuiÃ§Ã£o: load balancing dinÃ¢mico
  - Workers: `auto` (detecta nÃºmero de CPUs)

### Papers Relacionados

1. **Verdecchia et al. (2023)** - "A Systematic Review of Green Software Engineering"
   - DOI: 10.1007/s10664-023-10273-w

2. **Pinto & Castor (2017)** - "Energy Efficiency: A New Concern for Application Software Developers"
   - DOI: 10.1145/3028503

3. **Lima et al. (2019)** - "Test Prioritization in Continuous Integration Environments"
   - DOI: 10.1016/j.infsof.2019.05.013

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o repositÃ³rio
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add: Minha Feature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

**Ãreas para contribuiÃ§Ã£o:**
- Adicionar novos tratamentos (e.g., test prioritization)
- Implementar mÃ©tricas adicionais (e.g., memory footprint)
- Melhorar anÃ¡lises estatÃ­sticas (e.g., ANOVA, regressÃ£o)
- Criar dashboards interativos (e.g., Streamlit, Dash)


